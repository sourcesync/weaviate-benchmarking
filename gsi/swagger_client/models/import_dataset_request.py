# coding: utf-8

"""
    GSI Floating-Point 32 API

    **Introduction**<br> GSI Technology’s floating-point similarity search API provides an accessible gateway to running searches on GSI’s Gemini® Associative Processing Unit (APU).<br> It works in conjunction with the GSI system management solution which enables users to work with multiple APU boards simultaneously for improved performance.<br><br> **Dataset and Query Format**<br> Dataset embeddings can be in 32- or 64-bit floating point format, and any number of features, e.g. 256 or 512 (there is no upper limit).<br> Query embeddings must have the same floating-point format and number of features as used in the dataset.<br> GSI performs the search and delivers the top-k most similar results.  # noqa: E501

    OpenAPI spec version: 1.0
    
    Generated by: https://github.com/swagger-api/swagger-codegen.git
"""

import pprint
import re  # noqa: F401

import six

class ImportDatasetRequest(object):
    """NOTE: This class is auto generated by the swagger code generator program.

    Do not edit the class manually.
    """
    """
    Attributes:
      swagger_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    swagger_types = {
        'ds_file_path': 'str',
        'ds_file_type': 'str',
        'storage_type': 'str',
        'search_type': 'str',
        'train_ind': 'bool',
        'grid_train': 'bool',
        'nbits': 'int',
        'qbits': 'int',
        'target_accuracy': 'float',
        'md_file_path': 'str',
        'md_unique': 'bool',
        'convert_to_dataset': 'bool',
        'num_of_boards': 'int',
        'num_of_clusters': 'int',
        'dataset_name': 'str'
    }

    attribute_map = {
        'ds_file_path': 'dsFilePath',
        'ds_file_type': 'dsFileType',
        'storage_type': 'storageType',
        'search_type': 'searchType',
        'train_ind': 'trainInd',
        'grid_train': 'gridTrain',
        'nbits': 'nbits',
        'qbits': 'qbits',
        'target_accuracy': 'targetAccuracy',
        'md_file_path': 'mdFilePath',
        'md_unique': 'mdUnique',
        'convert_to_dataset': 'convertToDataset',
        'num_of_boards': 'numOfBoards',
        'num_of_clusters': 'numOfClusters',
        'dataset_name': 'datasetName'
    }

    def __init__(self, ds_file_path=None, ds_file_type=None, storage_type=None, search_type='flat', train_ind=False, grid_train=False, nbits=768, qbits=768, target_accuracy=100, md_file_path=None, md_unique=False, convert_to_dataset=False, num_of_boards=None, num_of_clusters=None, dataset_name=None):  # noqa: E501
        """ImportDatasetRequest - a model defined in Swagger"""  # noqa: E501
        self._ds_file_path = None
        self._ds_file_type = None
        self._storage_type = None
        self._search_type = None
        self._train_ind = None
        self._grid_train = None
        self._nbits = None
        self._qbits = None
        self._target_accuracy = None
        self._md_file_path = None
        self._md_unique = None
        self._convert_to_dataset = None
        self._num_of_boards = None
        self._num_of_clusters = None
        self._dataset_name = None
        self.discriminator = None
        self.ds_file_path = ds_file_path
        if ds_file_type is not None:
            self.ds_file_type = ds_file_type
        if storage_type is not None:
            self.storage_type = storage_type
        if search_type is not None:
            self.search_type = search_type
        if train_ind is not None:
            self.train_ind = train_ind
        if grid_train is not None:
            self.grid_train = grid_train
        if nbits is not None:
            self.nbits = nbits
        if qbits is not None:
            self.qbits = qbits
        if target_accuracy is not None:
            self.target_accuracy = target_accuracy
        if md_file_path is not None:
            self.md_file_path = md_file_path
        if md_unique is not None:
            self.md_unique = md_unique
        if convert_to_dataset is not None:
            self.convert_to_dataset = convert_to_dataset
        if num_of_boards is not None:
            self.num_of_boards = num_of_boards
        if num_of_clusters is not None:
            self.num_of_clusters = num_of_clusters
        if dataset_name is not None:
            self.dataset_name = dataset_name

    @property
    def ds_file_path(self):
        """Gets the ds_file_path of this ImportDatasetRequest.  # noqa: E501

        Path to file representing the dataset records.<br> File format should be .npy  # noqa: E501

        :return: The ds_file_path of this ImportDatasetRequest.  # noqa: E501
        :rtype: str
        """
        return self._ds_file_path

    @ds_file_path.setter
    def ds_file_path(self, ds_file_path):
        """Sets the ds_file_path of this ImportDatasetRequest.

        Path to file representing the dataset records.<br> File format should be .npy  # noqa: E501

        :param ds_file_path: The ds_file_path of this ImportDatasetRequest.  # noqa: E501
        :type: str
        """
        if ds_file_path is None:
            raise ValueError("Invalid value for `ds_file_path`, must not be `None`")  # noqa: E501

        self._ds_file_path = ds_file_path

    @property
    def ds_file_type(self):
        """Gets the ds_file_type of this ImportDatasetRequest.  # noqa: E501

        indicates the type of the data in the file. if no value will be set, read file will based file extension  # noqa: E501

        :return: The ds_file_type of this ImportDatasetRequest.  # noqa: E501
        :rtype: str
        """
        return self._ds_file_type

    @ds_file_type.setter
    def ds_file_type(self, ds_file_type):
        """Sets the ds_file_type of this ImportDatasetRequest.

        indicates the type of the data in the file. if no value will be set, read file will based file extension  # noqa: E501

        :param ds_file_type: The ds_file_type of this ImportDatasetRequest.  # noqa: E501
        :type: str
        """
        allowed_values = ["fvecs", "h5", "npy"]  # noqa: E501
        if ds_file_type not in allowed_values:
            raise ValueError(
                "Invalid value for `ds_file_type` ({0}), must be one of {1}"  # noqa: E501
                .format(ds_file_type, allowed_values)
            )

        self._ds_file_type = ds_file_type

    @property
    def storage_type(self):
        """Gets the storage_type of this ImportDatasetRequest.  # noqa: E501

        indicates the type of the storage, if S3 we need to download it to local filesystem  # noqa: E501

        :return: The storage_type of this ImportDatasetRequest.  # noqa: E501
        :rtype: str
        """
        return self._storage_type

    @storage_type.setter
    def storage_type(self, storage_type):
        """Sets the storage_type of this ImportDatasetRequest.

        indicates the type of the storage, if S3 we need to download it to local filesystem  # noqa: E501

        :param storage_type: The storage_type of this ImportDatasetRequest.  # noqa: E501
        :type: str
        """

        self._storage_type = storage_type

    @property
    def search_type(self):
        """Gets the search_type of this ImportDatasetRequest.  # noqa: E501

        Flag indicates if the dataset search type will be clustered or flat.  # noqa: E501

        :return: The search_type of this ImportDatasetRequest.  # noqa: E501
        :rtype: str
        """
        return self._search_type

    @search_type.setter
    def search_type(self, search_type):
        """Sets the search_type of this ImportDatasetRequest.

        Flag indicates if the dataset search type will be clustered or flat.  # noqa: E501

        :param search_type: The search_type of this ImportDatasetRequest.  # noqa: E501
        :type: str
        """
        allowed_values = ["flat", "clusters"]  # noqa: E501
        if search_type not in allowed_values:
            raise ValueError(
                "Invalid value for `search_type` ({0}), must be one of {1}"  # noqa: E501
                .format(search_type, allowed_values)
            )

        self._search_type = search_type

    @property
    def train_ind(self):
        """Gets the train_ind of this ImportDatasetRequest.  # noqa: E501

        Flag that indicates whether a dataset should be trained. (for float32 default is True, for other default is False)  # noqa: E501

        :return: The train_ind of this ImportDatasetRequest.  # noqa: E501
        :rtype: bool
        """
        return self._train_ind

    @train_ind.setter
    def train_ind(self, train_ind):
        """Sets the train_ind of this ImportDatasetRequest.

        Flag that indicates whether a dataset should be trained. (for float32 default is True, for other default is False)  # noqa: E501

        :param train_ind: The train_ind of this ImportDatasetRequest.  # noqa: E501
        :type: bool
        """

        self._train_ind = train_ind

    @property
    def grid_train(self):
        """Gets the grid_train of this ImportDatasetRequest.  # noqa: E501

        Flag that indicates whether the train should be optimized. Grid train is taking longer time than default train.  # noqa: E501

        :return: The grid_train of this ImportDatasetRequest.  # noqa: E501
        :rtype: bool
        """
        return self._grid_train

    @grid_train.setter
    def grid_train(self, grid_train):
        """Sets the grid_train of this ImportDatasetRequest.

        Flag that indicates whether the train should be optimized. Grid train is taking longer time than default train.  # noqa: E501

        :param grid_train: The grid_train of this ImportDatasetRequest.  # noqa: E501
        :type: bool
        """

        self._grid_train = grid_train

    @property
    def nbits(self):
        """Gets the nbits of this ImportDatasetRequest.  # noqa: E501

        If dataset is float, nbits is the value to convert the float dataset into  # noqa: E501

        :return: The nbits of this ImportDatasetRequest.  # noqa: E501
        :rtype: int
        """
        return self._nbits

    @nbits.setter
    def nbits(self, nbits):
        """Sets the nbits of this ImportDatasetRequest.

        If dataset is float, nbits is the value to convert the float dataset into  # noqa: E501

        :param nbits: The nbits of this ImportDatasetRequest.  # noqa: E501
        :type: int
        """

        self._nbits = nbits

    @property
    def qbits(self):
        """Gets the qbits of this ImportDatasetRequest.  # noqa: E501

        If dataset is float and search type is clusters, qbits is the value to convert the float centroids into  # noqa: E501

        :return: The qbits of this ImportDatasetRequest.  # noqa: E501
        :rtype: int
        """
        return self._qbits

    @qbits.setter
    def qbits(self, qbits):
        """Sets the qbits of this ImportDatasetRequest.

        If dataset is float and search type is clusters, qbits is the value to convert the float centroids into  # noqa: E501

        :param qbits: The qbits of this ImportDatasetRequest.  # noqa: E501
        :type: int
        """

        self._qbits = qbits

    @property
    def target_accuracy(self):
        """Gets the target_accuracy of this ImportDatasetRequest.  # noqa: E501

        Expected accuracy for optimal Hamming K calculation.  # noqa: E501

        :return: The target_accuracy of this ImportDatasetRequest.  # noqa: E501
        :rtype: float
        """
        return self._target_accuracy

    @target_accuracy.setter
    def target_accuracy(self, target_accuracy):
        """Sets the target_accuracy of this ImportDatasetRequest.

        Expected accuracy for optimal Hamming K calculation.  # noqa: E501

        :param target_accuracy: The target_accuracy of this ImportDatasetRequest.  # noqa: E501
        :type: float
        """

        self._target_accuracy = target_accuracy

    @property
    def md_file_path(self):
        """Gets the md_file_path of this ImportDatasetRequest.  # noqa: E501

        Path to a metadata file which will be associated with the dataset.  # noqa: E501

        :return: The md_file_path of this ImportDatasetRequest.  # noqa: E501
        :rtype: str
        """
        return self._md_file_path

    @md_file_path.setter
    def md_file_path(self, md_file_path):
        """Sets the md_file_path of this ImportDatasetRequest.

        Path to a metadata file which will be associated with the dataset.  # noqa: E501

        :param md_file_path: The md_file_path of this ImportDatasetRequest.  # noqa: E501
        :type: str
        """

        self._md_file_path = md_file_path

    @property
    def md_unique(self):
        """Gets the md_unique of this ImportDatasetRequest.  # noqa: E501

        indicating if the values in metadata are unique (vector-ids)  # noqa: E501

        :return: The md_unique of this ImportDatasetRequest.  # noqa: E501
        :rtype: bool
        """
        return self._md_unique

    @md_unique.setter
    def md_unique(self, md_unique):
        """Sets the md_unique of this ImportDatasetRequest.

        indicating if the values in metadata are unique (vector-ids)  # noqa: E501

        :param md_unique: The md_unique of this ImportDatasetRequest.  # noqa: E501
        :type: bool
        """

        self._md_unique = md_unique

    @property
    def convert_to_dataset(self):
        """Gets the convert_to_dataset of this ImportDatasetRequest.  # noqa: E501

        Indicating whether the input file should be converted to a dataset  # noqa: E501

        :return: The convert_to_dataset of this ImportDatasetRequest.  # noqa: E501
        :rtype: bool
        """
        return self._convert_to_dataset

    @convert_to_dataset.setter
    def convert_to_dataset(self, convert_to_dataset):
        """Sets the convert_to_dataset of this ImportDatasetRequest.

        Indicating whether the input file should be converted to a dataset  # noqa: E501

        :param convert_to_dataset: The convert_to_dataset of this ImportDatasetRequest.  # noqa: E501
        :type: bool
        """

        self._convert_to_dataset = convert_to_dataset

    @property
    def num_of_boards(self):
        """Gets the num_of_boards of this ImportDatasetRequest.  # noqa: E501

        Used to for cluster search only. numOfBoards will define the num of clusters to create.  # noqa: E501

        :return: The num_of_boards of this ImportDatasetRequest.  # noqa: E501
        :rtype: int
        """
        return self._num_of_boards

    @num_of_boards.setter
    def num_of_boards(self, num_of_boards):
        """Sets the num_of_boards of this ImportDatasetRequest.

        Used to for cluster search only. numOfBoards will define the num of clusters to create.  # noqa: E501

        :param num_of_boards: The num_of_boards of this ImportDatasetRequest.  # noqa: E501
        :type: int
        """

        self._num_of_boards = num_of_boards

    @property
    def num_of_clusters(self):
        """Gets the num_of_clusters of this ImportDatasetRequest.  # noqa: E501

        If numOfBoards is empty, numOfClusters will be used to define the num of clusters to create.  # noqa: E501

        :return: The num_of_clusters of this ImportDatasetRequest.  # noqa: E501
        :rtype: int
        """
        return self._num_of_clusters

    @num_of_clusters.setter
    def num_of_clusters(self, num_of_clusters):
        """Sets the num_of_clusters of this ImportDatasetRequest.

        If numOfBoards is empty, numOfClusters will be used to define the num of clusters to create.  # noqa: E501

        :param num_of_clusters: The num_of_clusters of this ImportDatasetRequest.  # noqa: E501
        :type: int
        """

        self._num_of_clusters = num_of_clusters

    @property
    def dataset_name(self):
        """Gets the dataset_name of this ImportDatasetRequest.  # noqa: E501

        Optional name to associated with the dataset id  # noqa: E501

        :return: The dataset_name of this ImportDatasetRequest.  # noqa: E501
        :rtype: str
        """
        return self._dataset_name

    @dataset_name.setter
    def dataset_name(self, dataset_name):
        """Sets the dataset_name of this ImportDatasetRequest.

        Optional name to associated with the dataset id  # noqa: E501

        :param dataset_name: The dataset_name of this ImportDatasetRequest.  # noqa: E501
        :type: str
        """

        self._dataset_name = dataset_name

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.swagger_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value
        if issubclass(ImportDatasetRequest, dict):
            for key, value in self.items():
                result[key] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, ImportDatasetRequest):
            return False

        return self.__dict__ == other.__dict__

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        return not self == other
